{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise postgres database (revolut:postgres/password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect('host=localhost dbname=revolut user=postgres password=password')\n",
    "# cur = conn.cursor()\n",
    "# engine = create_engine(\"postgresql://{user}:{pw}@localhost/{db}\"\n",
    "#                        .format(user=\"postgres\",\n",
    "#                                pw=\"password\",\n",
    "#                                db=\"revolut\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop existing tables\n",
    "# str_droptables = \"\"\"\n",
    "# GRANT ALL ON SCHEMA public TO postgres;\n",
    "# GRANT ALL ON SCHEMA public TO public;\n",
    "\n",
    "# DROP SCHEMA public CASCADE;\n",
    "# CREATE SCHEMA public;\n",
    "# \"\"\"\n",
    "# cur.execute(str_droptables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_createtables = \"\"\"\n",
    "# create table transactions (\n",
    "# currency character(3) not null,\n",
    "# amount bigint not null,\n",
    "# state varchar(25) not null,\n",
    "# created_date timestamp not null,\n",
    "# merchant_category varchar(100),\n",
    "# merchant_country varchar(3),\n",
    "# entry_method varchar(4) not null,\n",
    "# user_id uuid not null,\n",
    "# type varchar(20) not null,\n",
    "# source varchar(20) not null,\n",
    "# id uuid,\n",
    "# primary key (id)\n",
    "# );\n",
    "\n",
    "# create table users (\n",
    "# id uuid,\n",
    "# has_email boolean not null,\n",
    "# phone_country varchar(300),\n",
    "# terms_version date,\n",
    "# created_date timestamp not null,\n",
    "# state varchar(25) not null,\n",
    "# country varchar(2),\n",
    "# birth_year integer,\n",
    "# kyc varchar(20),\n",
    "# failed_sign_in_attempts integer,\n",
    "# primary key(id)\n",
    "# );\n",
    "\n",
    "# create table fx_rates (\n",
    "# base_ccy varchar(3),\n",
    "# ccy varchar(10),\n",
    "# rate double precision\n",
    "# );\n",
    "\n",
    "# create table currency_details (\n",
    "# ccy varchar(10),\n",
    "# iso_code integer,\n",
    "# exponent integer,\n",
    "# is_crypto boolean not null,\n",
    "# primary key (ccy)\n",
    "# );\n",
    "\n",
    "# create table countries (\n",
    "# code varchar(2),\n",
    "# name varchar(300) not null,\n",
    "# code3 varchar(3),\n",
    "# numcode integer,\n",
    "# phonecode integer\n",
    "# );\n",
    "# \"\"\"\n",
    "\n",
    "# cur.execute(str_createtables)\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv(r'countries.csv')\n",
    "# countries.to_sql('countries', con=engine, if_exists='append', index=False, chunksize=1000)\n",
    "currency_details = pd.read_csv(r'currency_details.csv')\n",
    "currency_details.rename(columns={'currency':'ccy'}, inplace=True)\n",
    "# currency_details.to_sql('currency_details', con=engine, if_exists='append', index=False, chunksize=1000)\n",
    "fx_rates = pd.read_csv(r'fx_rates.csv')\n",
    "# fx_rates.to_sql('fx_rates', con=engine, if_exists='append', index=False, chunksize=1000)\n",
    "transactions = pd.read_csv(r'transactions.csv')\n",
    "transactions.rename(columns={'CURRENCY':'currency','AMOUNT':'amount','STATE':'state','CREATED_DATE':'created_date','MERCHANT_CATEGORY':'merchant_category','MERCHANT_COUNTRY':'merchant_country','ENTRY_METHOD':'entry_method','USER_ID':'user_id','TYPE':'type','SOURCE':'source','ID':'id'}, inplace=True)\n",
    "users = pd.read_csv(r'users.csv')\n",
    "users.rename(columns={'id'.upper():'id','has_email'.upper():'has_email','phone_country'.upper():'phone_country','terms_version'.upper():'terms_version','created_date'.upper():'created_date','state'.upper():'state','country'.upper():'country','birth_year'.upper():'birth_year','kyc'.upper():'kyc','failed_sign_in_attempts'.upper():'failed_sign_in_attempts'}, inplace=True)\n",
    "\n",
    "# has_email field is boolean according to schema (currently 1/0: assume 1 => True)\n",
    "users['has_email'] = users['has_email']==1\n",
    "users = users.drop(columns='Unnamed: 0')\n",
    "\n",
    "# users.drop(columns='Unnamed: 0').to_sql('users', con=engine, if_exists='append', index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some merchant_country values are too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions['merchant_country'] = transactions['merchant_country'].str.slice(0,3)\n",
    "transaction_old = transactions.copy()\n",
    "transactions = transactions.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SQL Query FIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query Intention: Shows sum total transaction amounts in EUR each user made per country for transactions sourced from \"GAIA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original, non-working SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_query = \"\"\"\n",
    "# WITH processed_users\n",
    "# AS \n",
    "# (SELECT LEFT (u.phone_country , 2 ) AS short_phone_country ,\n",
    "# u.id\n",
    "# FROM users u)\n",
    "\n",
    "# SELECT t.user_id, t.merchant_country, Sum (t.amount / fx.rate / Power (10, cd.exponent)) AS amount\n",
    "# FROM transactions t\n",
    "\n",
    "# JOIN fx_rates fx\n",
    "# ON \n",
    "# (fx.ccy = t.currency\n",
    "# AND fx.base_ccy = 'EUR')\n",
    "\n",
    "# JOIN currency_details cd\n",
    "# ON cd.ccy = t.currency\n",
    "\n",
    "# JOIN processed_users pu\n",
    "# ON pu.id = t.user_id\n",
    "\n",
    "# WHERE t.source = 'GAIA'\n",
    "\n",
    "# AND pu.short_phone_country = t.merchant_country\n",
    "\n",
    "# GROUP BY t.user_id,\n",
    "# t.merchant_country\n",
    "\n",
    "# ORDER BY amount DESC;\n",
    "# \"\"\"\n",
    "# cur.execute(str_query)\n",
    "# results = cur.fetchall()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed errors: <br/>\n",
    "1.\"currency\" field does not exist in currency_details table (it's called \"ccy\" according to schema)<br/>2. Tries to join transaction table's \"merchant_country\" field (varchar(3)) to processed_users \"short_phone_country\" which has been setup as 2 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_query = \"\"\"\n",
    "# WITH processed_users\n",
    "# AS \n",
    "# (SELECT LEFT (u.phone_country , 2 ) AS short_phone_country, u.id\n",
    "# FROM users u)\n",
    "\n",
    "# SELECT t.user_id, t.merchant_country, Sum (t.amount / fx.rate / Power (10, cd.exponent)) AS amount\n",
    "# FROM transactions t\n",
    "\n",
    "# JOIN fx_rates fx\n",
    "# ON \n",
    "# (fx.ccy = t.currency\n",
    "# AND fx.base_ccy = 'EUR')\n",
    "\n",
    "# JOIN currency_details cd\n",
    "# ON cd.ccy = t.currency\n",
    "\n",
    "# JOIN processed_users pu\n",
    "# ON pu.id = t.user_id\n",
    "\n",
    "# WHERE t.source = 'GAIA'\n",
    "\n",
    "# AND pu.short_phone_country = left(t.merchant_country,2)\n",
    "\n",
    "# GROUP BY t.user_id,\n",
    "# t.merchant_country\n",
    "\n",
    "# ORDER BY amount DESC\n",
    "\n",
    "# LIMIT 10;\n",
    "# \"\"\"\n",
    "# cur.execute(str_query)\n",
    "# results = cur.fetchall()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Query to identify users whose first transaction was successful card payment over USD 10 equivalent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CARD_PAYMENT' 'P2P' 'TOPUP' 'ATM' 'BANK_TRANSFER']\n",
      "['COMPLETED' 'REVERTED' 'DECLINED' 'FAILED' 'RECORDED' 'CANCELLED'\n",
      " 'PENDING']\n"
     ]
    }
   ],
   "source": [
    "print(transactions['type'].unique())\n",
    "print(transactions['state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# str_query = \"\"\"\n",
    "\n",
    "# SELECT t.user_id, (t.amount / fx.rate / Power(10, cd.exponent)) AS USD_amount\n",
    "\n",
    "# FROM transactions t\n",
    "\n",
    "# JOIN fx_rates fx\n",
    "#     ON (fx.ccy = t.currency\n",
    "#     AND fx.base_ccy = 'USD')\n",
    "# JOIN currency_details cd\n",
    "#     ON cd.ccy = t.currency\n",
    "\n",
    "# JOIN\n",
    "# (\n",
    "# SELECT t.user_id, MIN(t.created_date) as first_tx\n",
    "# FROM transactions t\n",
    "# GROUP BY\n",
    "#     t.user_id\n",
    "# ) first_tx\n",
    "# ON\n",
    "#     first_tx.user_id = t.user_id\n",
    "#     AND\n",
    "#     first_tx.first_tx = t.created_date\n",
    "\n",
    "# WHERE\n",
    "#     (t.amount / fx.rate / Power(10, cd.exponent)) > 10\n",
    "#     AND\n",
    "#     t.type = 'CARD_PAYMENT'\n",
    "#     AND state = 'COMPLETED'\n",
    "\n",
    "# LIMIT 10\n",
    "# ;\n",
    "# \"\"\"\n",
    "\n",
    "# cur.execute(str_query)\n",
    "# results = cur.fetchall()\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(transactions[transactions['user_id']=='2eb7c137-056b-4a3f-9f98-f2bc4bc2d982'].sort_values(by=['created_date']).head(5))\n",
    "# print(transactions[transactions['user_id']=='484253ae-3dd7-402e-8565-0b2b612554b3'].sort_values(by=['created_date']).head(5))\n",
    "# print(transactions[transactions['user_id']=='de2e0774-a1e0-47a7-9d9a-bdb992aa3151'].sort_values(by=['created_date']).head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find 5 likely fraudsters (incomplete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables - converting using OneHotEncoding <br/>\n",
    "Test ML models to work out best performance and apply to datasets (transactions & users) to understand best predicting factors behind fraudulent transactions/users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fraudster list: only contains user_ids of fraudulent accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudsters = pd.read_csv(r'fraudsters.csv')\n",
    "fraudsters = fraudsters.drop(columns='Unnamed: 0')\n",
    "# fraudsters.to_sql('fraudsters', con=engine, if_exists='append', index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mark existing transactions to be able to merge with fraudulent transactions and distinguish\n",
    "transactions['marker'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.merge(fraudsters, transactions, on=['user_id'], how='left')\n",
    "# np.count_nonzero(joined.user_id.unique())\n",
    "joined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined[joined['marker']!=1])\n",
    "print(transactions[transactions['user_id']=='5270b0f4-2e4a-4ec9-8648-2135312ac1c4'])\n",
    "# this id is not found in the transactions log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tag fraudsters in transactions table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transactions.loc[transactions['user_id'].isin(fraudsters['user_id'])]\n",
    "transactions['fraud'] = 0\n",
    "transactions.loc[transactions['user_id'].isin(fraudsters['user_id']), 'fraud'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans = joined[joined['marker']==1].copy()\n",
    "# fraud_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = fraud_trans.drop(columns=['user_id','currency','created_date','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans_ord = fraud_trans.sort_values(by=['user_id', 'created_date', 'state']).drop('marker', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_trans_ord.groupby(['merchant_category'])['user_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(transactions['merchant_category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_1 = fraud_trans_ord.groupby(['merchant_category'])['user_id'].count().sort_values(ascending=False)\n",
    "tbl_2 = transactions.groupby(['merchant_category'])['user_id'].count().sort_values(ascending=False)\n",
    "merchant_tbl = pd.concat([tbl_2, tbl_1], axis=1, join='outer', names=['transactions'])\n",
    "merchant_tbl.columns = ['tx','fraud']\n",
    "merchant_tbl['% fraud'] = merchant_tbl['fraud']/merchant_tbl['tx']\n",
    "merchant_tbl.index.name = 'merchant'\n",
    "merchant_tbl.sort_values('% fraud', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(transactions['state'].unique())\n",
    "transactions['state'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_1 = fraud_trans_ord.groupby(['state'])['user_id'].count().sort_values(ascending=False)\n",
    "tbl_2 = transactions.groupby(['state'])['user_id'].count().sort_values(ascending=False)\n",
    "state_tbl = pd.concat([tbl_2, tbl_1], axis=1, join='outer', names=['transactions'])\n",
    "state_tbl.columns = ['tx','fraud']\n",
    "state_tbl['% fraud'] = state_tbl['fraud']/state_tbl['tx']\n",
    "state_tbl.index.name = 'tx state'\n",
    "state_tbl.sort_values('% fraud', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_1 = fraud_trans_ord.groupby('type')['user_id'].count().sort_values(ascending=False)\n",
    "tbl_2 = transactions.groupby('type')['user_id'].count().sort_values(ascending=False)\n",
    "type_tbl = pd.concat([tbl_2, tbl_1], axis=1, join='outer', names=['transactions'])\n",
    "type_tbl.columns = ['tx','fraud']\n",
    "type_tbl['% fraud'] = type_tbl['fraud']/type_tbl['tx']\n",
    "type_tbl.index.name = 'tx type'\n",
    "type_tbl.sort_values('% fraud', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.groupby('type')['user_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_1 = fraud_trans_ord.groupby('entry_method')['user_id'].count().sort_values(ascending=False)\n",
    "tbl_2 = transactions.groupby('entry_method')['user_id'].count().sort_values(ascending=False)\n",
    "entry_tbl = pd.concat([tbl_2, tbl_1], axis=1, join='outer', names=['transactions'])\n",
    "entry_tbl.columns = ['tx','fraud']\n",
    "entry_tbl['% fraud'] = entry_tbl['fraud']/entry_tbl['tx']\n",
    "entry_tbl.index.name = 'tx entry method'\n",
    "entry_tbl.sort_values('% fraud', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_1 = fraud_trans_ord.groupby('source')['user_id'].count().sort_values(ascending=False)\n",
    "tbl_2 = transactions.groupby('source')['user_id'].count().sort_values(ascending=False)\n",
    "source_tbl = pd.concat([tbl_2, tbl_1], axis=1, join='outer', names=['transactions'])\n",
    "source_tbl.columns = ['tx','fraud']\n",
    "source_tbl['% fraud'] = source_tbl['fraud']/source_tbl['tx']\n",
    "source_tbl.index.name = 'tx source'\n",
    "source_tbl.sort_values('% fraud', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get fraud indicator proportion for all user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_users = users.drop(columns={'Unnamed: 0'}).copy()\n",
    "f_users['fraud']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.merge(f_users, fraudsters, left_on=['id'], right_on=['user_id'], how='left')\n",
    "fr_users = joined.drop(columns={'user_id'})\n",
    "fr_users.loc[joined['user_id'].isin(fraudsters['user_id']), 'fraud'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_users.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_users['kyc'] = fr_users['kyc'].astype('category')\n",
    "fr_users['birth_year'] = fr_users['birth_year'].astype('category')\n",
    "fr_users['country'] = fr_users['country'].astype('category')\n",
    "fr_users['state'] = fr_users['state'].astype('category')\n",
    "fr_users['terms_version'] = fr_users['terms_version'].astype('category')\n",
    "fr_users['phone_country'] = fr_users['phone_country'].astype('category')\n",
    "fr_users['has_email'] = fr_users['has_email'].astype('category')\n",
    "fr_users['fraud'] = fr_users['fraud'].astype('category')\n",
    "fr_users['created_date'] = pd.to_datetime(fr_users['created_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fr_users['kyc'].unique())\n",
    "# print(fr_users['country'].unique())\n",
    "# print(fr_users['has_email'].unique())\n",
    "# print(fr_users['failed_sign_in_attempts'].unique())\n",
    "# print(fr_users['birth_year'].unique())\n",
    "\n",
    "for col in fr_users.columns:\n",
    "    print(col, ': ', len(fr_users[col].unique()), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_users = fr_users.drop(['country', 'created_date', 'phone_country', 'birth_year'], axis=1).dropna().copy()\n",
    "fra_users.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_top_x(df, variable, top_x_labels):\n",
    "    for label in top_x_labels:\n",
    "        df[variable+' '+str(label)] = np.where(df[variable]==label, 1, 0)\n",
    "\n",
    "# top_10 = [x for x in fr_users['birth_year'].value_counts().sort_values(ascending=False).head(50).index]\n",
    "one_hot_top_x(fra_users, 'failed_sign_in_attempts', [x for x in fra_users['failed_sign_in_attempts'].value_counts().sort_values(ascending=False).head(50).index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# t = ColumnTransformer(transformers=[\n",
    "#     ('onehot', OneHotEncoder(), ['kyc', 'birth_year', 'country', 'state', 'terms_version', 'phone_country', 'has_email', 'fraud']),\n",
    "#     ('scale', StandardScaler(), ['fraud','failed_sign_in_attempts', 'created_date', 'id'])\n",
    "# ], remainder='passthrough')\n",
    "\n",
    "# # t.fit_transform(fr_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(fra_users.drop('fraud', axis=1), fra_users['fraud'], test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "baseline = DummyClassifier(strategy='most_frequent', random_state=0).fit(X_train, y_train)\n",
    "y_pred = baseline.predict(X_test)\n",
    "print(round(accuracy_score(y_test, y_pred),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True)\n",
    "#     NuSVC(probability=True),\n",
    "#     DecisionTreeClassifier(),\n",
    "#     RandomForestClassifier(),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GradientBoostingClassifier()\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
